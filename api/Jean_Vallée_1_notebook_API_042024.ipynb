{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deecde96-b66b-4adb-b8db-b1000f664e8a"
   },
   "source": [
    "<center>\n",
    "  <font size=\"7\">Déploiement d'API du modèle</font><br>\n",
    "  <font size=\"5\">Projet 7 - Implémentez un modèle de scoring</font>\n",
    "</center>\n",
    "<div align=\"right\">\n",
    "  <font size=\"4\"><i>par Jean Vallée</i></font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0052b662-95c8-4ea4-9ac9-6bfe8b4364d1"
   },
   "source": [
    "<hr size=5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'API REST sert d'interface d'échange de requêtes et reponses avec le modèle \n",
    "- est disponible en ligne au développeur et aux utilisateurs\n",
    "- c'est la classe Python du modèle avec ses méthodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outils de déploiement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- les commandes Git pour la gestion de versions du code et de l’API\n",
    "- [Github](https://github.com/) pour stocker et partager l’API et assurer une intégration continue\n",
    "- [Github Actions](https://github.com/JeanRosselVallee/project_7/actions) pour le déploiement en continu de l’API\n",
    "- Pytest\n",
    "    - des jeux de tests unitaires sont préparés dans ce notebook\n",
    "    - des tests unitaires sont exécutés par le Notebook N°5 Test d'API\n",
    "    - les tests automatisés font partie des jobs du [workflow](https://github.com/JeanRosselVallee/project_7/blob/main/.github/workflows/python-app-test-%26-deploy.yml) de GitHub Actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-requis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_staging = './staging_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlflow==2.14.1 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from -r ./staging_model/requirements.txt (line 1)) (2.14.1)\n",
      "Requirement already satisfied: cloudpickle==3.0.0 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from -r ./staging_model/requirements.txt (line 2)) (3.0.0)\n",
      "Requirement already satisfied: numpy==1.26.4 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from -r ./staging_model/requirements.txt (line 3)) (1.26.4)\n",
      "Requirement already satisfied: packaging==23.2 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from -r ./staging_model/requirements.txt (line 4)) (23.2)\n",
      "Requirement already satisfied: pandas==2.2.2 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from -r ./staging_model/requirements.txt (line 5)) (2.2.2)\n",
      "Requirement already satisfied: pyyaml==6.0.1 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from -r ./staging_model/requirements.txt (line 6)) (6.0.1)\n",
      "Requirement already satisfied: scikit-learn==1.5.0 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from -r ./staging_model/requirements.txt (line 7)) (1.5.0)\n",
      "Requirement already satisfied: scipy==1.13.1 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from -r ./staging_model/requirements.txt (line 8)) (1.13.1)\n",
      "Requirement already satisfied: xgboost==2.1.0 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from -r ./staging_model/requirements.txt (line 9)) (2.1.0)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (2.32.3)\n",
      "Requirement already satisfied: pytz<2025 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (2024.1)\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (3.1.4)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (3.6)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (2.0.30)\n",
      "Requirement already satisfied: Flask<4 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (3.0.3)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (1.25.0)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (5.3.3)\n",
      "Requirement already satisfied: gunicorn<23 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (22.0.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (1.25.0)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (0.5.0)\n",
      "Requirement already satisfied: pyarrow<16,>=4.0.0 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (15.0.2)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (7.1.0)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (7.1.0)\n",
      "Requirement already satisfied: matplotlib<4 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (3.9.0)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (3.1.43)\n",
      "Requirement already satisfied: click<9,>=7.0 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (8.1.7)\n",
      "Requirement already satisfied: entrypoints<1 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (0.4)\n",
      "Requirement already satisfied: querystring-parser<2 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (1.2.4)\n",
      "Requirement already satisfied: protobuf<5,>=3.12.0 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (4.25.3)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (1.13.1)\n",
      "Requirement already satisfied: graphene<4 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (3.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from pandas==2.2.2->-r ./staging_model/requirements.txt (line 5)) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from pandas==2.2.2->-r ./staging_model/requirements.txt (line 5)) (2024.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from scikit-learn==1.5.0->-r ./staging_model/requirements.txt (line 7)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from scikit-learn==1.5.0->-r ./staging_model/requirements.txt (line 7)) (3.5.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from xgboost==2.1.0->-r ./staging_model/requirements.txt (line 9)) (2.22.3)\n",
      "Requirement already satisfied: typing-extensions>=4 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (4.12.1)\n",
      "Requirement already satisfied: Mako in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (1.3.5)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from docker<8,>=4.0.0->mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (2.2.1)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from Flask<4->mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (3.0.3)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from Flask<4->mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (1.8.2)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from Flask<4->mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (2.2.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from gitpython<4,>=3.1.9->mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (4.0.11)\n",
      "Requirement already satisfied: aniso8601<10,>=8 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from graphene<4->mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (9.0.1)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from graphene<4->mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (3.2.0)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from graphene<4->mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (3.2.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (3.19.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from Jinja2<4,>=2.11->mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (2.1.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from matplotlib<4->mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (0.12.1)\n",
      "Requirement already satisfied: pillow>=8 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from matplotlib<4->mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from matplotlib<4->mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (3.1.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from matplotlib<4->mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (1.4.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from matplotlib<4->mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (1.2.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from matplotlib<4->mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (4.53.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from opentelemetry-api<3,>=1.9.0->mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (1.2.14)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.46b0 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (0.46b0)\n",
      "Requirement already satisfied: six>=1.5 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas==2.2.2->-r ./staging_model/requirements.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (3.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (2024.6.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from sqlalchemy<3,>=1.4.0->mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (3.0.3)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow==2.14.1->-r ./staging_model/requirements.txt (line 1)) (5.0.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install -r $dir_staging/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../config.json') as file_object:\n",
    "    dict_config = json.load(file_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_server       = dict_config['ip_host']\n",
    "user            = dict_config['user']\n",
    "port_staging    = dict_config['port_staging']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serveur de Staging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! pip install --quiet -r ./staging_model/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mlflow.pyfunc.loaded_model:\n",
       "  flavor: mlflow.sklearn"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "staging_model = mlflow.pyfunc.load_model(dir_staging)\n",
    "staging_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vérification de la signature\n",
    "\n",
    "La signature du modèle chargé indique les valeurs valides à lui fournir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attributs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CODE_GENDER_M',\n",
       " 'EXT_SOURCE_3',\n",
       " 'EXT_SOURCE_2',\n",
       " 'NAME_EDUCATION_TYPE_Secondary_or_secondary_special',\n",
       " 'NAME_EDUCATION_TYPE_Higher_education',\n",
       " 'NAME_CONTRACT_TYPE_Cash_loans',\n",
       " 'NAME_INCOME_TYPE_Working']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li_features = staging_model.metadata.get_input_schema().input_names()\n",
    "li_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Cible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Schema.input_names of ['TARGET': long (required)]>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "staging_model.metadata.get_output_schema().input_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vérification de prédiction\n",
    "\n",
    "On prédit la cible pour une observation issue du fichier des prédictions _True Positive_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_TP = '../modeling/data/out/X_TP.csv'\n",
    "df_TP = pd.read_csv(path_TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CODE_GENDER_M</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXT_SOURCE_3</th>\n",
       "      <td>0.202087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EXT_SOURCE_2</th>\n",
       "      <td>0.580628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAME_EDUCATION_TYPE_Secondary_or_secondary_special</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAME_EDUCATION_TYPE_Higher_education</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAME_CONTRACT_TYPE_Cash_loans</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NAME_INCOME_TYPE_Working</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           0\n",
       "CODE_GENDER_M                                       1.000000\n",
       "EXT_SOURCE_3                                        0.202087\n",
       "EXT_SOURCE_2                                        0.580628\n",
       "NAME_EDUCATION_TYPE_Secondary_or_secondary_special  1.000000\n",
       "NAME_EDUCATION_TYPE_Higher_education                0.000000\n",
       "NAME_CONTRACT_TYPE_Cash_loans                       1.000000\n",
       "NAME_INCOME_TYPE_Working                            1.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_TP_sample_1 = df_TP.head(1)\n",
    "df_TP_sample_1.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted target value = [1]\n"
     ]
    }
   ],
   "source": [
    "print('Predicted target value =', str(staging_model.predict(df_TP_sample_1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparation des tests unitaires\n",
    "Dans ce notebook,\n",
    "- les tests unitaires ne s'y dérouleront pas\n",
    "- les données destinées aux tests sont sauvegardées dans des fichiers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_test_data = '../test_api/data/'\n",
    "! mkdir -p $dir_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Liste d'attributs\n",
    "Ce fichier sera utilisé par la page _form.html_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CODE_GENDER_M', 'EXT_SOURCE_3', 'EXT_SOURCE_2', 'NAME_EDUCATION_TYPE_Secondary_or_secondary_special', 'NAME_EDUCATION_TYPE_Higher_education', 'NAME_CONTRACT_TYPE_Cash_loans', 'NAME_INCOME_TYPE_Working']\n"
     ]
    }
   ],
   "source": [
    "str_li_features = str(li_features)\n",
    "print(str_li_features)\n",
    "with open(dir_test_data + '/li_features.txt', \"w\") as file_form:\n",
    "    print(str_li_features, file=file_form)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Liste de types\n",
    "Ce fichier sera utilisé par la page _form.html_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[long, double, double, long, long, long, long]\n"
     ]
    }
   ],
   "source": [
    "li_types = staging_model.metadata.get_input_schema().input_types()\n",
    "str_li_types = str(li_types)\n",
    "print(str_li_types)\n",
    "with open(dir_test_data + '/li_types.txt', \"w\") as file_form:\n",
    "    print(str_li_types, file=file_form)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dictionnaire simple d'observations\n",
    "Ce fichier sera utilisé par le test unitaire de connexion du script _test_1.py_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"CODE_GENDER_M\":1,\"EXT_SOURCE_3\":0.2020866017,\"EXT_SOURCE_2\":0.5806283659,\"NAME_EDUCATION_TYPE_Secondary_or_secondary_special\":1,\"NAME_EDUCATION_TYPE_Higher_education\":0,\"NAME_CONTRACT_TYPE_Cash_loans\":1,\"NAME_INCOME_TYPE_Working\":1}]\n"
     ]
    }
   ],
   "source": [
    "str_features_values = df_TP_sample_1.to_json(orient='records')\n",
    "print(str_features_values)\n",
    "with open(dir_test_data + '/dict_X_single.json', 'w') as file_object:\n",
    "    print(str_features_values, file=file_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dictionnaire multiple d'observations\n",
    "- Ce fichier sera utilisé par les tests unitaires du script _test_2.py_\n",
    "- Il est obtenu à partir des résultats TP (vrais positifs) des prédictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODE_GENDER_M</th>\n",
       "      <th>EXT_SOURCE_3</th>\n",
       "      <th>EXT_SOURCE_2</th>\n",
       "      <th>NAME_EDUCATION_TYPE_Secondary_or_secondary_special</th>\n",
       "      <th>NAME_EDUCATION_TYPE_Higher_education</th>\n",
       "      <th>NAME_CONTRACT_TYPE_Cash_loans</th>\n",
       "      <th>NAME_INCOME_TYPE_Working</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2355</th>\n",
       "      <td>0</td>\n",
       "      <td>0.218859</td>\n",
       "      <td>0.588678</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2356</th>\n",
       "      <td>1</td>\n",
       "      <td>0.510853</td>\n",
       "      <td>0.367941</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2357</th>\n",
       "      <td>0</td>\n",
       "      <td>0.070109</td>\n",
       "      <td>0.030184</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CODE_GENDER_M  EXT_SOURCE_3  EXT_SOURCE_2  \\\n",
       "2355              0      0.218859      0.588678   \n",
       "2356              1      0.510853      0.367941   \n",
       "2357              0      0.070109      0.030184   \n",
       "\n",
       "      NAME_EDUCATION_TYPE_Secondary_or_secondary_special  \\\n",
       "2355                                                  1    \n",
       "2356                                                  1    \n",
       "2357                                                  0    \n",
       "\n",
       "      NAME_EDUCATION_TYPE_Higher_education  NAME_CONTRACT_TYPE_Cash_loans  \\\n",
       "2355                                     0                              1   \n",
       "2356                                     0                              1   \n",
       "2357                                     1                              1   \n",
       "\n",
       "      NAME_INCOME_TYPE_Working  \n",
       "2355                         1  \n",
       "2356                         1  \n",
       "2357                         0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_observations = 3\n",
    "df_TP_sample_N = df_TP.tail(nb_observations)\n",
    "df_TP_sample_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 ../test_api/data/X_sample.csv\n"
     ]
    }
   ],
   "source": [
    "file_TP_sample = dir_test_data + 'X_sample.csv'\n",
    "df_TP_sample_N.to_csv(file_TP_sample)\n",
    "! wc -l $file_TP_sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"CODE_GENDER_M\":0,\"EXT_SOURCE_3\":0.2188590822,\"EXT_SOURCE_2\":0.588678411,\"NAME_EDUCATION_TYPE_Secondary_or_secondary_special\":1,\"NAME_EDUCATION_TYPE_Higher_education\":0,\"NAME_CONTRACT_TYPE_Cash_loans\":1,\"NAME_INCOME_TYPE_Working\":1},{\"CODE_GENDER_M\":1,\"EXT_SOURCE_3\":0.5108529062,\"EXT_SOURCE_2\":0.3679405554,\"NAME_EDUCATION_TYPE_Secondary_or_secondary_special\":1,\"NAME_EDUCATION_TYPE_Higher_education\":0,\"NAME_CONTRACT_TYPE_Cash_loans\":1,\"NAME_INCOME_TYPE_Working\":1},{\"CODE_GENDER_M\":0,\"EXT_SOURCE_3\":0.0701088438,\"EXT_SOURCE_2\":0.0301835653,\"NAME_EDUCATION_TYPE_Secondary_or_secondary_special\":0,\"NAME_EDUCATION_TYPE_Higher_education\":1,\"NAME_CONTRACT_TYPE_Cash_loans\":1,\"NAME_INCOME_TYPE_Working\":0}]\n"
     ]
    }
   ],
   "source": [
    "str_features_values = df_TP_sample_N.to_json(orient='records')\n",
    "print(str_features_values)\n",
    "with open(dir_test_data + '/dict_X_sample.json', 'w') as file_object:\n",
    "    print(str_features_values, file=file_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lancement du serveur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Arrêt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ':' + port_staging\n",
    "! pkill -f \"$mask\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Démarrage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_host = '0.0.0.0'\n",
    "shell_command = 'nohup mlflow models serve -m ' + dir_staging + ' -p ' + port_staging + ' -h ' + ip_host\n",
    "get_ipython().system_raw(shell_command + ' --no-conda &')          # runs model API in background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vérification d'exécution**\n",
    "\n",
    "Il y a 2 processus qui tournent par serveur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69336 0.0.0.0:5677 mlflow.pyfunc.scoring_server.wsgi:app\n",
      "69337 0.0.0.0:5677 mlflow.pyfunc.scoring_server.wsgi:app\n"
     ]
    }
   ],
   "source": [
    "! ps aux | grep \"scoring_server\" | grep -v \"grep\" | awk '{print $2, $15, $19}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration réseau\n",
    "### Tunnel SSH\n",
    "Sur le terminal [_Azure CLI_](https://portal.azure.com/#cloudshell/) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nohup ssh -v -N -L 5677:localhost:5677 jvisa4031@4.233.201.217 &\n"
     ]
    }
   ],
   "source": [
    "shell_command = 'nohup ssh -v -N -L ' + port_staging + ':localhost:' + port_staging + \\\n",
    "                    ' ' + user + '@' + ip_server + ' &'\n",
    "print(shell_command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aperture de ports\n",
    "Sur le [portail _Azure_](https://portal.azure.com/), _Network Settings_ de la VM : _Create Inbound Port Rule_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Destination Port = 5677\n"
     ]
    }
   ],
   "source": [
    "print('Destination Port =', port_staging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## URL de l'API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL Staging    -> http://4.233.201.217:5677/invocations\n"
     ]
    }
   ],
   "source": [
    "url_staging = ip_server + ':' + port_staging + '/invocations'\n",
    "print('URL Staging    -> http://' + url_staging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vérification d'accès distant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demande par requête POST de prédiction de la cible pour une observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"columns\":[\"CODE_GENDER_M\",\"EXT_SOURCE_3\",\"EXT_SOURCE_2\",\"NAME_EDUCATION_TYPE_Secondary_or_secondary_special\",\"NAME_EDUCATION_TYPE_Higher_education\",\"NAME_CONTRACT_TYPE_Cash_loans\",\"NAME_INCOME_TYPE_Working\"],\"index\":[0],\"data\":[[1,0.2020866017,0.5806283659,1,0,1,1]]}\n"
     ]
    }
   ],
   "source": [
    "str_features_values = df_TP_sample_1.to_json(orient='split')\n",
    "print(str_features_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'{\"dataframe_split\": {\"columns\":[\"CODE_GENDER_M\",\"EXT_SOURCE_3\",\"EXT_SOURCE_2\",\"NAME_EDUCATION_TYPE_Secondary_or_secondary_special\",\"NAME_EDUCATION_TYPE_Higher_education\",\"NAME_CONTRACT_TYPE_Cash_loans\",\"NAME_INCOME_TYPE_Working\"],\"index\":[0],\"data\":[[1,0.2020866017,0.5806283659,1,0,1,1]]}}' \n"
     ]
    }
   ],
   "source": [
    "str_data = '\\'{\"dataframe_split\": ' + str_features_values + '}\\' '\n",
    "print(str_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copier cette ligne de commande Linux sur un terminal local et vérifier qu'elle renvoie une cible prédite = 1 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curl -d'{\"dataframe_split\": {\"columns\":[\"CODE_GENDER_M\",\"EXT_SOURCE_3\",\"EXT_SOURCE_2\",\"NAME_EDUCATION_TYPE_Secondary_or_secondary_special\",\"NAME_EDUCATION_TYPE_Higher_education\",\"NAME_CONTRACT_TYPE_Cash_loans\",\"NAME_INCOME_TYPE_Working\"],\"index\":[0],\"data\":[[1,0.2020866017,0.5806283659,1,0,1,1]]}}' -H 'Content-Type: application/json' -X POST 4.233.201.217:5677/invocations\n"
     ]
    }
   ],
   "source": [
    "print('curl -d' + str_data + '''-H 'Content-Type: application/json' -X POST ''' + url_staging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serveur de production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le déploiment sur le serveur de Production a besoin pour se déclencher de :\n",
    "- la publication via _git-push_ d'une nouvelle version du modèle vers le serveur de Staging\n",
    "- la réussite des tests unitaires "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_production = './production_model'\n",
    "port_production = dict_config['port_production']\n",
    "! mkdir -p $dir_production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! cp ./staging_model/* ./production_model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mlflow.pyfunc.loaded_model:\n",
       "  flavor: mlflow.sklearn"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "production_model = mlflow.pyfunc.load_model(dir_production)\n",
    "production_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vérification de la signature**\n",
    "\n",
    "La signature du modèle chargé indique les valeurs valides à lui fournir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attributs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CODE_GENDER_M',\n",
       " 'EXT_SOURCE_3',\n",
       " 'EXT_SOURCE_2',\n",
       " 'NAME_EDUCATION_TYPE_Secondary_or_secondary_special',\n",
       " 'NAME_EDUCATION_TYPE_Higher_education',\n",
       " 'NAME_CONTRACT_TYPE_Cash_loans',\n",
       " 'NAME_INCOME_TYPE_Working']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li_features = production_model.metadata.get_input_schema().input_names()\n",
    "li_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Cible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Schema.input_names of ['TARGET': long (required)]>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "production_model.metadata.get_output_schema().input_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vérification de prédiction**\n",
    "\n",
    "On prédit la cible pour une observation TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "production_model.predict(df_TP_sample_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lancement du serveur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Arrêt du serveur**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ':' + port_production\n",
    "! pkill -f \"$mask\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Démarrage**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_host, port_production = '0.0.0.0', '5678'\n",
    "shell_command = 'mlflow models serve -m ' + dir_production + ' -p ' + port_production + ' -h ' + ip_host\n",
    "get_ipython().system_raw(shell_command + ' --no-conda &')          # runs model API in background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vérification d'exécution**\n",
    "\n",
    "Il y a 2 processus qui tournent par serveur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70156 0.0.0.0:5677 mlflow.pyfunc.scoring_server.wsgi:app\n",
      "70157 0.0.0.0:5677 mlflow.pyfunc.scoring_server.wsgi:app\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 5/5 [00:00<00:00, 10397.38it/s]\n",
      "2024/07/02 22:50:25 INFO mlflow.models.flavor_backend_registry: Selected backend for flavor 'python_function'\n",
      "2024/07/02 22:50:25 INFO mlflow.pyfunc.backend: === Running command 'exec gunicorn --timeout=60 -b 0.0.0.0:5678 -w 1 ${GUNICORN_CMD_ARGS} -- mlflow.pyfunc.scoring_server.wsgi:app'\n",
      "[2024-07-02 22:50:25 +0000] [70505] [INFO] Starting gunicorn 22.0.0\n",
      "[2024-07-02 22:50:25 +0000] [70505] [INFO] Listening at: http://0.0.0.0:5678 (70505)\n",
      "[2024-07-02 22:50:25 +0000] [70505] [INFO] Using worker: sync\n",
      "[2024-07-02 22:50:25 +0000] [70506] [INFO] Booting worker with pid: 70506\n"
     ]
    }
   ],
   "source": [
    "! ps aux | grep \"scoring_server\" | grep -v \"grep\" | awk '{print $2, $15, $19}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration réseau\n",
    "### Tunnel SSH\n",
    "Sur le terminal [_Azure CLI_](https://portal.azure.com/#cloudshell/) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssh -v -N -L 5678:localhost:5678 azureuser@4.233.201.217\n"
     ]
    }
   ],
   "source": [
    "shell_command = 'ssh -v -N -L ' + port_production + ':localhost:' + port_production + ' azureuser@' + ip_server\n",
    "print(shell_command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aperture de ports\n",
    "Sur le [portail _Azure_](https://portal.azure.com/), _Network Settings_ de la VM : _Create Inbound Port Rule_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Destination Port = 5678\n"
     ]
    }
   ],
   "source": [
    "print('Destination Port =', port_production)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## URL de l'API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL Production    -> http://4.233.201.217:5678/invocations\n"
     ]
    }
   ],
   "source": [
    "url_production = ip_server + ':' + port_production + '/invocations'\n",
    "print('URL Production    -> http://' + url_production)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vérification d'accès distant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demande par requête POST de prédiction de la cible pour une observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"columns\":[\"CODE_GENDER_M\",\"EXT_SOURCE_3\",\"EXT_SOURCE_2\",\"NAME_EDUCATION_TYPE_Secondary_or_secondary_special\",\"NAME_EDUCATION_TYPE_Higher_education\",\"NAME_CONTRACT_TYPE_Cash_loans\",\"NAME_INCOME_TYPE_Working\"],\"index\":[0],\"data\":[[1,0.2020866017,0.5806283659,1,0,1,1]]}\n"
     ]
    }
   ],
   "source": [
    "str_features_values = df_TP_sample_1.to_json(orient='split')\n",
    "print(str_features_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'{\"dataframe_split\": {\"columns\":[\"CODE_GENDER_M\",\"EXT_SOURCE_3\",\"EXT_SOURCE_2\",\"NAME_EDUCATION_TYPE_Secondary_or_secondary_special\",\"NAME_EDUCATION_TYPE_Higher_education\",\"NAME_CONTRACT_TYPE_Cash_loans\",\"NAME_INCOME_TYPE_Working\"],\"index\":[0],\"data\":[[1,0.2020866017,0.5806283659,1,0,1,1]]}}' \n"
     ]
    }
   ],
   "source": [
    "str_data = '\\'{\"dataframe_split\": ' + str_features_values + '}\\' '\n",
    "print(str_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copier cette ligne de commande Linux sur un terminal local :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curl -d'{\"dataframe_split\": {\"columns\":[\"CODE_GENDER_M\",\"EXT_SOURCE_3\",\"EXT_SOURCE_2\",\"NAME_EDUCATION_TYPE_Secondary_or_secondary_special\",\"NAME_EDUCATION_TYPE_Higher_education\",\"NAME_CONTRACT_TYPE_Cash_loans\",\"NAME_INCOME_TYPE_Working\"],\"index\":[0],\"data\":[[1,0.2020866017,0.5806283659,1,0,1,1]]}}' -H 'Content-Type: application/json' -X POST 4.233.201.217:5678/invocations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-07-02 23:05:22 +0000] [70156] [INFO] Handling signal: term\n",
      "[2024-07-02 23:05:22 +0000] [70157] [INFO] Worker exiting (pid: 70157)\n",
      "[2024-07-02 23:05:22 +0000] [70156] [INFO] Shutting down: Master\n",
      "[2024-07-02 23:05:35 +0000] [70505] [INFO] Handling signal: term\n",
      "[2024-07-02 23:05:35 +0000] [70506] [INFO] Worker exiting (pid: 70506)\n",
      "[2024-07-02 23:05:36 +0000] [70505] [INFO] Shutting down: Master\n"
     ]
    }
   ],
   "source": [
    "print('curl -d' + str_data + '''-H 'Content-Type: application/json' -X POST ''' + url_production)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5cNyXYM9zlF"
   },
   "source": [
    "<a name=\"Current_Cell\"></a>\n",
    "<hr color=\"red\" size=5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjz3f_X5HkFa"
   },
   "source": [
    "# Fin du traitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "executionInfo": {
     "elapsed": 284,
     "status": "error",
     "timestamp": 1713256883996,
     "user": {
      "displayName": "Jean Vallée",
      "userId": "09369690285448182876"
     },
     "user_tz": -120
    },
    "id": "Ubs3bkasHeR1",
    "outputId": "a53ae3c6-07d7-4c06-e6ed-7f245b37748a"
   },
   "outputs": [],
   "source": [
    "assert(False) # prevents the execution of following cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GgDFI_ctDgx1"
   },
   "source": [
    "# Annexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Déploiement via MLFlow UI\n",
    "La version du modèle peut être mise à disposition par _MLFlow UI_ afin d'être déployée \n",
    "\n",
    "**Instructions sous _MLFlow UI_ :**\n",
    "1. click sur le _run_ du modèle à déployer\n",
    "2. onglet \"_Artifacts_\", click sur le bouton \"_Register_\"\n",
    "    - nommer le modèle à déployer \"ml_model_to_deploy\"\n",
    "3. lancer le service du modèle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ji7M93U5DkVS"
   },
   "source": [
    "## Référentiel d'évaluation\n",
    "Remarque : le chiffre des dizaines a été ajouté aux références CE originales pour mieux les différencier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pkWz1jxDvbM"
   },
   "source": [
    "Définir la stratégie d’élaboration d’un modèle d’apprentissage supervisé et sélectionner et entraîner des modèles adaptés à une problématique métier afin de réaliser une analyse prédictive.\n",
    "CE1 Les variables catégorielles identifiées ont été transformées en fonction du besoin (par exemple via OneHotEncoder ou TargetEncoder).\n",
    "\n",
    "CE2 Vous avez a créé de nouvelles variables à partir de variables existantes.\n",
    "\n",
    "CE3 Vous avez réalisé des transformations mathématiques lorsque c'est requis pour transformer les distributions de variables.\n",
    "\n",
    "CE4 Vous avez normalisé les variables lorsque c'est requis.\n",
    "\n",
    "CE5 Vous avez défini sa stratégie d’élaboration d’un modèle pour répondre à un besoin métier. Cela signifie dans ce projet que :\n",
    "\n",
    "l’étudiant a présenté son approche méthodologique de modélisation dans son support de présentation pendant la soutenance et est capable de répondre à des questions à ce sujet, si elles lui sont posées.\n",
    "CE6 Vous avez choisi la ou les variables cibles pertinentes.\n",
    "\n",
    "CE7 Vous avez vérifié qu'il n’y a pas de problème de data leakage (c'est-à-dire, des variables trop corrélées à la variable cible et inconnues a priori dans les données en entrée du modèle).\n",
    "\n",
    "CE8 Vous avez testé plusieurs algorithmes de façon cohérente, en partant des plus simples vers les plus complexes (au minimum un linéaire et un non linéaire).\n",
    "\n",
    "\n",
    "\n",
    "Évaluer les performances des modèles d’apprentissage supervisé selon différents critères (scores, temps d'entraînement, etc.) en adaptant les paramètres afin de choisir le modèle le plus performant pour la problématique métier.\n",
    "\n",
    "CE1 Vous avez choisi une métrique adaptée pour évaluer la performance d'un algorithme (par exemple : R2 ou RMSE en régression, accuracy ou AUC en classification, etc.). Dans le cadre de ce projet, cela signifie que :\n",
    "\n",
    "Vous avez mis en oeuvre un score métier pour évaluer les modèles et optimiser les hyperparamètres, qui prend en compte les spécificités du contexte, en particulier le fait que le coût d’un faux négatif et d’un faux positif sont sensiblement différents.\n",
    "CE2 Vous avez exploré d'autres indicateurs de performance que le score pour comprendre les résultats (coefficients des variables en fonction de la pénalisation, visualisation des erreurs en fonction des variables du modèle, temps de calcul...).\n",
    "\n",
    "CE3 Vous avez séparé les données en train/test pour les évaluer de façon pertinente et détecter l'overfitting.\n",
    "\n",
    "CE4 Vous avez mis en place un modèle simple de référence pour évaluer le pouvoir prédictif du modèle choisi (dummyRegressor ou dummyClassifier).\n",
    "\n",
    "CE5 Vous avez pris en compte dans sa démarche de modélisation l'éventuel déséquilibre des classes (dans le cas d'une classification).\n",
    "\n",
    "CE6 Vous avez optimisé les hyper-paramètres pertinents dans les différents algorithmes.\n",
    "\n",
    "CE7 Vous avez mis en place une validation croisée (via GridsearchCV, RandomizedSearchCV ou équivalent) afin d’optimiser les hyperparamètres et comparer les modèles. Dans le cadre de ce projet :\n",
    "\n",
    "une cross-validation du dataset train est réalisée ;\n",
    "un premier test de différentes valeurs d’hyperparamètres est réalisé sur chaque algorithme testé, et affiné pour l’algorithme final choisi ;\n",
    "tout projet présentant un score AUC anormalement élevé, démontrant de l’overfitting dans le GrisSearchCV, sera invalidé (il ne devrait pas être supérieur au meilleur de la compétition Kaggle : 0.82).\n",
    "CE8 Vous avez présenté l'ensemble des résultats en allant des modèles les plus simples aux plus complexes. Vous avez justifié le choix final de l'algorithme et des hyperparamètres.\n",
    "\n",
    "CE9 Vous avez réalisé l’analyse de l’importance des variables (feature importance) globale sur l’ensemble du jeu de données et locale sur chaque individu du jeu de données.\n",
    "\n",
    "\n",
    "\n",
    "Définir et mettre en œuvre un pipeline d’entraînement des modèles, avec centralisation du stockage des modèles et formalisation des résultats et mesures des différentes expérimentations réalisées, afin d’industrialiser le projet de Machine Learning.\n",
    "CE1 Vous avez mis en oeuvre un pipeline d’entraînement des modèles reproductible.\n",
    "\n",
    "CE2 Vous avez sérialisé et stocké les modèles créés dans un registre centralisé afin de pouvoir facilement les réutiliser.\n",
    "\n",
    "CE3 Vous avez formalisé des mesures et résultats de chaque expérimentation, afin de les analyser et de les comparer\n",
    "\n",
    "\n",
    "\n",
    "Mettre en œuvre un logiciel de version de code afin d’assurer en continu l’intégration et la diffusion du modèle auprès de collaborateurs.\n",
    "CE1 Vous avez créé un dossier contenant tous les scripts du projet dans un logiciel de version de code avec Git et l'a partagé avec Github.\n",
    "\n",
    "CE2 Vous avez présenté un historique des modifications du projet qui affiche au moins trois versions distinctes, auxquelles il est possible d'accéder.\n",
    "\n",
    "CE3 Vous avez tenu à jour et mis à disposition la liste des packages utilisés ainsi que leur numéro de version.\n",
    "\n",
    "CE4 Vous avez rédigé un fichier introductif permettant de comprendre l'objectif du projet et le découpage des dossiers.\n",
    "\n",
    "CE5 Vous avez commenté les scripts et les fonctions facilitant une réutilisation du travail par d'autres personnes et la collaboration.\n",
    "\n",
    "\n",
    "\n",
    "Concevoir et assurer un déploiement continu d'un moteur d’inférence (modèle de prédiction encapsulé dans une API) sur une plateforme Cloud afin de permettre à des applications de réaliser des prédictions via une requête à l’API.\n",
    "\n",
    "CE1 Vous avez défini et préparé un pipeline de déploiement continu.\n",
    "\n",
    "CE2 Vous avez déployé le modèle de machine learning sous forme d'API (via Flask par exemple) et cette API renvoie bien une prédiction correspondant à une demande.\n",
    "\n",
    "CE3 Vous avez mis en œuvre un pipeline de déploiement continu, afin de déployer l'API sur un serveur d'une plateforme Cloud.\n",
    "\n",
    "CE4 Vous avez mis en oeuvre des tests unitaires automatisés (par exemple avec pyTest).\n",
    "\n",
    "CE5 Vous avez réalisé l'API indépendamment de l'application qui utilise le résultat de la prédiction.\n",
    "\n",
    "\n",
    "\n",
    "Définir et mettre en œuvre une stratégie de suivi de la performance d’un modèle en production et en assurer la maintenance afin de garantir dans le temps la production de prédictions performantes.\n",
    "\n",
    "CE1 Vous avez défini une stratégie de suivi de la performance du modèle. Dans le cadre du projet :\n",
    "choix de réaliser a priori cette analyse sur le dataset disponible : analyse de data drift entre le dataset train et le dataset test.\n",
    "\n",
    "CE2 Vous avez réalisé un système de stockage d’événements relatifs aux prédictions réalisées par l’API et une gestion d’alerte en cas de dégradation significative de la performance. Dans le cadre du projet :\n",
    "choix de réaliser a priori cette analyse analyse de data drift, via une simulation dans un notebook et création d’un tableau HTML d’analyse avec la librairie evidently.\n",
    "\n",
    "CE3 Vous avez analysé la stabilité du modèle dans le temps et défini des actions d’amélioration de sa performance. Dans le cadre de ce projet :\n",
    "analyse du tableau HTML evidently, et conclusion sur un éventuel data drift."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1FpefMnpx1QrWxHvQHv_Km0XsNPZwS-GH",
     "timestamp": 1707857231301
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
