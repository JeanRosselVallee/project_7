{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deecde96-b66b-4adb-b8db-b1000f664e8a"
   },
   "source": [
    "<center>\n",
    "  <font size=\"7\">Déploiement du modèle</font><br>\n",
    "  <font size=\"5\">Projet 7 - Implémentez un modèle de scoring</font>\n",
    "</center>\n",
    "<div align=\"right\">\n",
    "  <font size=\"4\"><i>par Jean Vallée</i></font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0052b662-95c8-4ea4-9ac9-6bfe8b4364d1"
   },
   "source": [
    "<hr size=5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-requis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlflow==2.13.1\n",
      "  Downloading mlflow-2.13.1-py3-none-any.whl (25.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.0/25.0 MB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: cloudpickle==3.0.0 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from -r ./staging_model/requirements.txt (line 2)) (3.0.0)\n",
      "Collecting numpy==1.24.4\n",
      "  Downloading numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting packaging==23.2\n",
      "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 KB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pandas==2.0.3\n",
      "  Downloading pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting psutil==5.9.0\n",
      "  Downloading psutil-5.9.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 KB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml==6.0.1 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from -r ./staging_model/requirements.txt (line 7)) (6.0.1)\n",
      "Collecting scikit-learn==1.3.2\n",
      "  Downloading scikit_learn-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m120.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting scipy==1.10.1\n",
      "  Downloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: xgboost==2.0.3 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from -r ./staging_model/requirements.txt (line 10)) (2.0.3)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (0.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (8.1.7)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (7.1.0)\n",
      "Requirement already satisfied: Flask<4 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (3.0.3)\n",
      "Requirement already satisfied: entrypoints<1 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (0.4)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (2.32.3)\n",
      "Requirement already satisfied: pyarrow<16,>=4.0.0 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (15.0.2)\n",
      "Requirement already satisfied: graphene<4 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (3.3)\n",
      "Requirement already satisfied: protobuf<5,>=3.12.0 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (4.25.3)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (3.6)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.0.0 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (1.25.0)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (7.1.0)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (5.3.3)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (2.0.30)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.0.0 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (1.25.0)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (3.1.43)\n",
      "Requirement already satisfied: gunicorn<23 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (22.0.0)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (1.13.1)\n",
      "Requirement already satisfied: querystring-parser<2 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (1.2.4)\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (3.1.4)\n",
      "Requirement already satisfied: pytz<2025 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (2024.1)\n",
      "Requirement already satisfied: matplotlib<4 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (3.9.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from pandas==2.0.3->-r ./staging_model/requirements.txt (line 5)) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from pandas==2.0.3->-r ./staging_model/requirements.txt (line 5)) (2024.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from scikit-learn==1.3.2->-r ./staging_model/requirements.txt (line 8)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from scikit-learn==1.3.2->-r ./staging_model/requirements.txt (line 8)) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (4.12.1)\n",
      "Requirement already satisfied: Mako in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from alembic!=1.10.0,<2->mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (1.3.5)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from docker<8,>=4.0.0->mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (2.2.1)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from Flask<4->mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (2.2.0)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from Flask<4->mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (3.0.3)\n",
      "Requirement already satisfied: blinker>=1.6.2 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from Flask<4->mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (1.8.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from gitpython<4,>=3.1.9->mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (4.0.11)\n",
      "Requirement already satisfied: aniso8601<10,>=8 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from graphene<4->mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (9.0.1)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from graphene<4->mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (3.2.3)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from graphene<4->mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (3.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (3.19.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from Jinja2<4,>=2.11->mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (2.1.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from matplotlib<4->mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from matplotlib<4->mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (1.4.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from matplotlib<4->mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from matplotlib<4->mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (0.12.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from matplotlib<4->mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (3.1.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from matplotlib<4->mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (10.3.0)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from opentelemetry-api<3,>=1.0.0->mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (1.2.14)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.46b0 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from opentelemetry-sdk<3,>=1.0.0->mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (0.46b0)\n",
      "Requirement already satisfied: six>=1.5 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas==2.0.3->-r ./staging_model/requirements.txt (line 5)) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (2024.6.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from requests<3,>=2.17.3->mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (3.3.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from sqlalchemy<3,>=1.4.0->mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (3.0.3)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.0.0->mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (1.16.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/jvisa4031/environments_folder/my_env/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow==2.13.1->-r ./staging_model/requirements.txt (line 1)) (5.0.1)\n",
      "Installing collected packages: psutil, packaging, numpy, scipy, pandas, scikit-learn, mlflow\n",
      "  Attempting uninstall: psutil\n",
      "    Found existing installation: psutil 5.9.8\n",
      "    Uninstalling psutil-5.9.8:\n",
      "      Successfully uninstalled psutil-5.9.8\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.0\n",
      "    Uninstalling packaging-24.0:\n",
      "      Successfully uninstalled packaging-24.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.13.1\n",
      "    Uninstalling scipy-1.13.1:\n",
      "      Successfully uninstalled scipy-1.13.1\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.2.2\n",
      "    Uninstalling pandas-2.2.2:\n",
      "      Successfully uninstalled pandas-2.2.2\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.5.0\n",
      "    Uninstalling scikit-learn-1.5.0:\n",
      "      Successfully uninstalled scikit-learn-1.5.0\n",
      "  Attempting uninstall: mlflow\n",
      "    Found existing installation: mlflow 2.13.2\n",
      "    Uninstalling mlflow-2.13.2:\n",
      "      Successfully uninstalled mlflow-2.13.2\n",
      "Successfully installed mlflow-2.13.1 numpy-1.24.4 packaging-23.2 pandas-2.0.3 psutil-5.9.0 scikit-learn-1.3.2 scipy-1.10.1\n"
     ]
    }
   ],
   "source": [
    "! pip install -r $dir_staging/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('../config.json') as file_object:\n",
    "    dict_config = json.load(file_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_server       = dict_config['ip_host']\n",
    "user            = dict_config['user']\n",
    "port_staging    = dict_config['port_staging']\n",
    "dir_staging = './staging_model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serveur de Staging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mlflow.pyfunc.loaded_model:\n",
       "  flavor: mlflow.sklearn"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "staging_model = mlflow.pyfunc.load_model(dir_staging)\n",
    "staging_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vérification de la signature\n",
    "\n",
    "La signature du modèle chargé indique les valeurs valides à lui fournir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attributs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CODE_GENDER_M',\n",
       " 'NAME_CONTRACT_TYPE_Cash_loans',\n",
       " 'NAME_EDUCATION_TYPE_Lower_secondary',\n",
       " 'EXT_SOURCE_3',\n",
       " 'NAME_EDUCATION_TYPE_Higher_education',\n",
       " 'NAME_EDUCATION_TYPE_Secondary_or_secondary_special']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li_features = staging_model.metadata.get_input_schema().input_names()\n",
    "li_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Cible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Schema.input_names of ['TARGET': long (required)]>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "staging_model.metadata.get_output_schema().input_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vérification de prédiction\n",
    "\n",
    "On prédit la cible pour une observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted target value = [0]\n"
     ]
    }
   ],
   "source": [
    "df_observation = pd.DataFrame(np.array([[1, 1, 0, 1.0, 1, 0]]).astype('int'), columns=li_features)\n",
    "df_observation['EXT_SOURCE_3'] = df_observation['EXT_SOURCE_3'].astype('double')  # double~float64\n",
    "print('Predicted target value =', str(staging_model.predict(df_observation)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparation des tests unitaires\n",
    "Dans ce notebook,\n",
    "- les tests unitaires ne s'y dérouleront pas\n",
    "- les données destinées aux tests sont sauvegardées dans des fichiers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_test_data = '../test_api/data/'\n",
    "! mkdir -p $dir_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Liste d'attributs\n",
    "Ce fichier sera utilisé par la page _form.html_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CODE_GENDER_M', 'NAME_CONTRACT_TYPE_Cash_loans', 'NAME_EDUCATION_TYPE_Lower_secondary', 'EXT_SOURCE_3', 'NAME_EDUCATION_TYPE_Higher_education', 'NAME_EDUCATION_TYPE_Secondary_or_secondary_special']\n"
     ]
    }
   ],
   "source": [
    "str_li_features = str(li_features)\n",
    "print(str_li_features)\n",
    "with open(dir_test_data + '/li_features.txt', \"w\") as file_form:\n",
    "    print(str_li_features, file=file_form)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Liste de types\n",
    "Ce fichier sera utilisé par la page _form.html_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[long, long, long, double, long, long]\n"
     ]
    }
   ],
   "source": [
    "li_types = staging_model.metadata.get_input_schema().input_types()\n",
    "str_li_types = str(li_types)\n",
    "print(str_li_types)\n",
    "with open(dir_test_data + '/li_types.txt', \"w\") as file_form:\n",
    "    print(str_li_types, file=file_form)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dictionnaire simple d'observations\n",
    "Ce fichier sera utilisé par le test unitaire de connexion du script _test_1.py_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"CODE_GENDER_M\":1,\"NAME_CONTRACT_TYPE_Cash_loans\":1,\"NAME_EDUCATION_TYPE_Lower_secondary\":0,\"EXT_SOURCE_3\":1.0,\"NAME_EDUCATION_TYPE_Higher_education\":1,\"NAME_EDUCATION_TYPE_Secondary_or_secondary_special\":0}]\n"
     ]
    }
   ],
   "source": [
    "str_features_values = df_observation.to_json(orient='records')\n",
    "print(str_features_values)\n",
    "with open(dir_test_data + '/dict_X_single.json', 'w') as file_object:\n",
    "    print(str_features_values, file=file_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dictionnaire multiple d'observations\n",
    "- Ce fichier sera utilisé par les tests unitaires du script _test_2.py_\n",
    "- Il est obtenu à partir des résultats TP (vrais positifs) des prédictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_observations = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 ../test_api/data/X_sample.csv\n"
     ]
    }
   ],
   "source": [
    "file_X_train = '../modeling/data/out/X_true_pos.csv'\n",
    "file_X_sample = dir_test_data + 'X_sample.csv'\n",
    "nb_file_lines = nb_observations + 1\n",
    "! head -n $nb_file_lines $file_X_train > $file_X_sample\n",
    "! wc -l $file_X_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CODE_GENDER_M</th>\n",
       "      <th>NAME_CONTRACT_TYPE_Cash_loans</th>\n",
       "      <th>NAME_EDUCATION_TYPE_Lower_secondary</th>\n",
       "      <th>EXT_SOURCE_3</th>\n",
       "      <th>NAME_EDUCATION_TYPE_Higher_education</th>\n",
       "      <th>NAME_EDUCATION_TYPE_Secondary_or_secondary_special</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.135951</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.244516</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.248536</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CODE_GENDER_M  NAME_CONTRACT_TYPE_Cash_loans  \\\n",
       "0              0                              1   \n",
       "1              0                              1   \n",
       "2              0                              1   \n",
       "\n",
       "   NAME_EDUCATION_TYPE_Lower_secondary  EXT_SOURCE_3  \\\n",
       "0                                    1      0.135951   \n",
       "1                                    1      0.244516   \n",
       "2                                    1      0.248536   \n",
       "\n",
       "   NAME_EDUCATION_TYPE_Higher_education  \\\n",
       "0                                     0   \n",
       "1                                     0   \n",
       "2                                     0   \n",
       "\n",
       "   NAME_EDUCATION_TYPE_Secondary_or_secondary_special  \n",
       "0                                                  0   \n",
       "1                                                  0   \n",
       "2                                                  0   "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_X_sample = pd.read_csv(file_X_sample).drop('Unnamed: 0', axis='columns')\n",
    "df_X_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"CODE_GENDER_M\":0,\"NAME_CONTRACT_TYPE_Cash_loans\":1,\"NAME_EDUCATION_TYPE_Lower_secondary\":1,\"EXT_SOURCE_3\":0.1359510442,\"NAME_EDUCATION_TYPE_Higher_education\":0,\"NAME_EDUCATION_TYPE_Secondary_or_secondary_special\":0},{\"CODE_GENDER_M\":0,\"NAME_CONTRACT_TYPE_Cash_loans\":1,\"NAME_EDUCATION_TYPE_Lower_secondary\":1,\"EXT_SOURCE_3\":0.244516392,\"NAME_EDUCATION_TYPE_Higher_education\":0,\"NAME_EDUCATION_TYPE_Secondary_or_secondary_special\":0},{\"CODE_GENDER_M\":0,\"NAME_CONTRACT_TYPE_Cash_loans\":1,\"NAME_EDUCATION_TYPE_Lower_secondary\":1,\"EXT_SOURCE_3\":0.2485355573,\"NAME_EDUCATION_TYPE_Higher_education\":0,\"NAME_EDUCATION_TYPE_Secondary_or_secondary_special\":0}]\n"
     ]
    }
   ],
   "source": [
    "str_features_values = df_X_sample.to_json(orient='records')\n",
    "print(str_features_values)\n",
    "with open(dir_test_data + '/dict_X_sample.json', 'w') as file_object:\n",
    "    print(str_features_values, file=file_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lancement du serveur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 6/6 [00:00<00:00, 8895.66it/s] \n",
      "2024/06/06 21:59:28 INFO mlflow.models.flavor_backend_registry: Selected backend for flavor 'python_function'\n",
      "2024/06/06 21:59:28 INFO mlflow.pyfunc.backend: === Running command 'exec gunicorn --timeout=60 -b 0.0.0.0:5677 -w 1 ${GUNICORN_CMD_ARGS} -- mlflow.pyfunc.scoring_server.wsgi:app'\n",
      "[2024-06-06 21:59:28 +0000] [5163] [INFO] Starting gunicorn 22.0.0\n",
      "[2024-06-06 21:59:28 +0000] [5163] [INFO] Listening at: http://0.0.0.0:5677 (5163)\n",
      "[2024-06-06 21:59:28 +0000] [5163] [INFO] Using worker: sync\n",
      "[2024-06-06 21:59:28 +0000] [5164] [INFO] Booting worker with pid: 5164\n"
     ]
    }
   ],
   "source": [
    "ip_host = '0.0.0.0'\n",
    "shell_command = 'nohup mlflow models serve -m ' + dir_staging + ' -p ' + port_staging + ' -h ' + ip_host\n",
    "get_ipython().system_raw(shell_command + ' --no-conda &')          # runs model API in background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vérification d'exécution**\n",
    "\n",
    "Il y a 2 processus qui tournent par serveur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5163 0.0.0.0:5677 mlflow.pyfunc.scoring_server.wsgi:app\n",
      "5164 0.0.0.0:5677 mlflow.pyfunc.scoring_server.wsgi:app\n"
     ]
    }
   ],
   "source": [
    "! ps aux | grep \"scoring_server\" | grep -v \"grep\" | awk '{print $2, $15, $19}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Arrêt du serveur**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-06-06 21:59:22 +0000] [4795] [INFO] Worker exiting (pid: 4795)\n",
      "[2024-06-06 21:59:22 +0000] [4794] [INFO] Handling signal: term\n",
      "[2024-06-06 21:59:22 +0000] [4794] [INFO] Shutting down: Master\n"
     ]
    }
   ],
   "source": [
    "mask = ':' + port_staging\n",
    "#! pkill -f \"$mask\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration réseau\n",
    "### Tunnel SSH\n",
    "Sur le terminal [_Azure CLI_](https://portal.azure.com/#cloudshell/) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nohup ssh -v -N -L 5677:localhost:5677 jvisa4031@4.233.201.217 &\n"
     ]
    }
   ],
   "source": [
    "shell_command = 'nohup ssh -v -N -L ' + port_staging + ':localhost:' + port_staging + \\\n",
    "                    ' ' + user + '@' + ip_server + ' &'\n",
    "print(shell_command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aperture de ports\n",
    "Sur le [portail _Azure_](https://portal.azure.com/), _Network Settings_ de la VM : _Create Inbound Port Rule_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Destination Port = 5677\n"
     ]
    }
   ],
   "source": [
    "print('Destination Port =', port_staging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vérification d'accès distant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demande par requête POST de prédiction de la cible pour une observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL Staging    -> http://4.233.201.217:5677/invocations\n"
     ]
    }
   ],
   "source": [
    "url_staging = ip_server + ':' + port_staging + '/invocations'\n",
    "print('URL Staging    -> http://' + url_staging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Données de l'observation en entrée "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"columns\":[\"CODE_GENDER_M\",\"NAME_CONTRACT_TYPE_Cash_loans\",\"NAME_EDUCATION_TYPE_Lower_secondary\",\"EXT_SOURCE_3\",\"NAME_EDUCATION_TYPE_Higher_education\",\"NAME_EDUCATION_TYPE_Secondary_or_secondary_special\"],\"index\":[0],\"data\":[[1,1,0,1.0,1,0]]}\n"
     ]
    }
   ],
   "source": [
    "str_features_values = df_observation.to_json(orient='split')\n",
    "print(str_features_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'{\"dataframe_split\": {\"columns\":[\"CODE_GENDER_M\",\"NAME_CONTRACT_TYPE_Cash_loans\",\"NAME_EDUCATION_TYPE_Lower_secondary\",\"EXT_SOURCE_3\",\"NAME_EDUCATION_TYPE_Higher_education\",\"NAME_EDUCATION_TYPE_Secondary_or_secondary_special\"],\"index\":[0],\"data\":[[1,1,0,1.0,1,0]]}}' \n"
     ]
    }
   ],
   "source": [
    "str_data = '\\'{\"dataframe_split\": ' + str_features_values + '}\\' '\n",
    "print(str_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copier cette ligne de commande Linux sur un terminal local :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curl -d'{\"dataframe_split\": {\"columns\":[\"CODE_GENDER_M\",\"NAME_CONTRACT_TYPE_Cash_loans\",\"NAME_EDUCATION_TYPE_Lower_secondary\",\"EXT_SOURCE_3\",\"NAME_EDUCATION_TYPE_Higher_education\",\"NAME_EDUCATION_TYPE_Secondary_or_secondary_special\"],\"index\":[0],\"data\":[[1,1,0,1.0,1,0]]}}' -H 'Content-Type: application/json' -X POST 4.233.201.217:5677/invocations\n"
     ]
    }
   ],
   "source": [
    "print('curl -d' + str_data + '''-H 'Content-Type: application/json' -X POST ''' + url_staging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serveur de production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le déploiment sur le serveur de Production a besoin pour se déclencher de :\n",
    "- la publication via _git-push_ d'une nouvelle version du modèle vers le serveur de Staging\n",
    "- la réussite des tests unitaires "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_production = './production_model'\n",
    "port_production = dict_config['port_production']\n",
    "! mkdir -p $dir_production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "MlflowException",
     "evalue": "Could not find an \"MLmodel\" configuration file at \"/home/jvisa4031/project_7/api/production_model/MLmodel\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m production_model \u001b[38;5;241m=\u001b[39m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdir_production\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m production_model\n",
      "File \u001b[0;32m~/environments_folder/my_env/lib/python3.10/site-packages/mlflow/pyfunc/__init__.py:985\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model_uri, suppress_warnings, dst_path, model_config)\u001b[0m\n\u001b[1;32m    982\u001b[0m     model_requirements \u001b[38;5;241m=\u001b[39m _get_pip_requirements_from_model_path(local_path)\n\u001b[1;32m    983\u001b[0m     warn_dependency_requirement_mismatches(model_requirements)\n\u001b[0;32m--> 985\u001b[0m model_meta \u001b[38;5;241m=\u001b[39m \u001b[43mModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMLMODEL_FILE_NAME\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    987\u001b[0m conf \u001b[38;5;241m=\u001b[39m model_meta\u001b[38;5;241m.\u001b[39mflavors\u001b[38;5;241m.\u001b[39mget(FLAVOR_NAME)\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/environments_folder/my_env/lib/python3.10/site-packages/mlflow/models/model.py:588\u001b[0m, in \u001b[0;36mModel.load\u001b[0;34m(cls, path)\u001b[0m\n\u001b[1;32m    586\u001b[0m path_scheme \u001b[38;5;241m=\u001b[39m urlparse(\u001b[38;5;28mstr\u001b[39m(path))\u001b[38;5;241m.\u001b[39mscheme\n\u001b[1;32m    587\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m path_scheme \u001b[38;5;129;01mor\u001b[39;00m path_scheme \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(path):\n\u001b[0;32m--> 588\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    589\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCould not find an \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mMLMODEL_FILE_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m configuration file at \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    590\u001b[0m         RESOURCE_DOES_NOT_EXIST,\n\u001b[1;32m    591\u001b[0m     )\n\u001b[1;32m    593\u001b[0m path \u001b[38;5;241m=\u001b[39m download_artifacts(artifact_uri\u001b[38;5;241m=\u001b[39mpath)\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(path):\n",
      "\u001b[0;31mMlflowException\u001b[0m: Could not find an \"MLmodel\" configuration file at \"/home/jvisa4031/project_7/api/production_model/MLmodel\""
     ]
    }
   ],
   "source": [
    "production_model = mlflow.pyfunc.load_model(dir_production)\n",
    "production_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vérification de la signature**\n",
    "\n",
    "La signature du modèle chargé indique les valeurs valides à lui fournir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attributs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li_features = production_model.metadata.get_input_schema().input_names()\n",
    "li_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Cible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "production_model.metadata.get_output_schema().input_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vérification de prédiction**\n",
    "\n",
    "On prédit la cible pour une observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_observation = pd.DataFrame(np.array([[1, 1, 0, 1.0, 1, 0]]).astype('int'), columns=li_features)\n",
    "df_observation['EXT_SOURCE_3'] = df_observation['EXT_SOURCE_3'].astype('double')  # double~float64\n",
    "production_model.predict(df_observation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lancement du serveur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_host, port_production = '0.0.0.0', '5678'\n",
    "shell_command = 'mlflow models serve -m ' + dir_production + ' -p ' + port_production + ' -h ' + ip_host\n",
    "get_ipython().system_raw(shell_command + ' --no-conda &')          # runs model API in background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vérification d'exécution**\n",
    "\n",
    "Il y a 2 processus qui tournent par serveur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ps aux | grep \"scoring_server\" | grep -v \"grep\" | awk '{print $2, $15, $19}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Arrêt du serveur**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ':' + port_production\n",
    "#! pkill -f \"$mask\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration réseau\n",
    "### Tunnel SSH\n",
    "Sur le terminal [_Azure CLI_](https://portal.azure.com/#cloudshell/) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'port_production' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m shell_command \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mssh -v -N -L \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[43mport_production\u001b[49m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:localhost:\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m port_production \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m azureuser@\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m ip_server\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(shell_command)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'port_production' is not defined"
     ]
    }
   ],
   "source": [
    "shell_command = 'ssh -v -N -L ' + port_production + ':localhost:' + port_production + ' azureuser@' + ip_server\n",
    "print(shell_command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aperture de ports\n",
    "Sur le [portail _Azure_](https://portal.azure.com/), _Network Settings_ de la VM : _Create Inbound Port Rule_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Destination Port =', port_production)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vérification d'accès distant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Demande par requête POST de prédiction de la cible pour une observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_production = ip_server + ':' + port_production + '/invocations'\n",
    "print('URL Production    -> http://' + url_production)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Données de l'observation en entrée "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_features_values = df_observation.to_json(orient='split')\n",
    "print(str_features_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_data = '\\'{\"dataframe_split\": ' + str_features_values + '}\\' '\n",
    "print(str_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copier cette ligne de commande Linux sur un terminal local :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('curl -d' + str_data + '''-H 'Content-Type: application/json' -X POST ''' + url_production)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0052b662-95c8-4ea4-9ac9-6bfe8b4364d1"
   },
   "source": [
    "<hr color=\"gold\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HGy3Z1Hp2aby"
   },
   "source": [
    "# Notes RAF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fzf7P9v62ab7"
   },
   "source": [
    "L’API de prédiction du score, déployée sur le cloud (lien vers l’API).\n",
    "\n",
    "Un dossier, géré via un outil de versioning de code contenant :\n",
    "- Le notebook ou code de la modélisation (du prétraitement à la prédiction),\n",
    "- intégrant via MLFlow le tracking d’expérimentations et le stockage centralisé des modèles.\n",
    "- Le code permettant de déployer le modèle sous forme d'API. Pour l’API,\n",
    "    - un fichier introductif permettant de comprendre l'objectif du projet et\n",
    "    - le découpage des dossiers, et\n",
    "    - un fichier listant les packages utilisés\n",
    "- Le tableau HTML d’analyse de data drift réalisé à partir d’evidently.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xWKaZaOImTBP"
   },
   "source": [
    "<a name=\"Current_Cell\"></a>\n",
    "<hr color=\"red\" size=2>\n",
    "\n",
    "Aller vers >> [Modules&fonctions](#Fonctions) >> [Sauvegarde N°1](#Restore_1) >> [Sauvegarde N°2](#Restore_2) >> [En cours](#Current_Cell)\n",
    "<hr color=\"red\" size=2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5cNyXYM9zlF"
   },
   "source": [
    "<a name=\"Current_Cell\"></a>\n",
    "<hr color=\"red\" size=25>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjz3f_X5HkFa"
   },
   "source": [
    "# Fin du traitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "executionInfo": {
     "elapsed": 284,
     "status": "error",
     "timestamp": 1713256883996,
     "user": {
      "displayName": "Jean Vallée",
      "userId": "09369690285448182876"
     },
     "user_tz": -120
    },
    "id": "Ubs3bkasHeR1",
    "outputId": "a53ae3c6-07d7-4c06-e6ed-7f245b37748a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 5/5 [00:00<00:00, 8272.79it/s] \n",
      "2024/06/06 18:11:07 INFO mlflow.models.flavor_backend_registry: Selected backend for flavor 'python_function'\n",
      "2024/06/06 18:11:07 INFO mlflow.pyfunc.backend: === Running command 'exec gunicorn --timeout=60 -b 0.0.0.0:5677 -w 1 ${GUNICORN_CMD_ARGS} -- mlflow.pyfunc.scoring_server.wsgi:app'\n",
      "[2024-06-06 18:11:07 +0000] [7354] [INFO] Starting gunicorn 22.0.0\n",
      "[2024-06-06 18:11:07 +0000] [7354] [INFO] Listening at: http://0.0.0.0:5677 (7354)\n",
      "[2024-06-06 18:11:07 +0000] [7354] [INFO] Using worker: sync\n",
      "[2024-06-06 18:11:07 +0000] [7355] [INFO] Booting worker with pid: 7355\n"
     ]
    }
   ],
   "source": [
    "assert(False) # prevents the execution of following cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GgDFI_ctDgx1"
   },
   "source": [
    "# Annexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Déploiement via MLFlow UI\n",
    "La version du modèle peut être mise à disposition par _MLFlow UI_ afin d'être déployée \n",
    "\n",
    "**Instructions sous _MLFlow UI_ :**\n",
    "1. click sur le _run_ du modèle à déployer\n",
    "2. onglet \"_Artifacts_\", click sur le bouton \"_Register_\"\n",
    "    - nommer le modèle à déployer \"ml_model_to_deploy\"\n",
    "3. lancer le service du modèle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ji7M93U5DkVS"
   },
   "source": [
    "## Référentiel d'évaluation\n",
    "Remarque : le chiffre des dizaines a été ajouté aux références CE originales pour mieux les différencier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pkWz1jxDvbM"
   },
   "source": [
    "Définir la stratégie d’élaboration d’un modèle d’apprentissage supervisé et sélectionner et entraîner des modèles adaptés à une problématique métier afin de réaliser une analyse prédictive.\n",
    "CE1 Les variables catégorielles identifiées ont été transformées en fonction du besoin (par exemple via OneHotEncoder ou TargetEncoder).\n",
    "\n",
    "CE2 Vous avez a créé de nouvelles variables à partir de variables existantes.\n",
    "\n",
    "CE3 Vous avez réalisé des transformations mathématiques lorsque c'est requis pour transformer les distributions de variables.\n",
    "\n",
    "CE4 Vous avez normalisé les variables lorsque c'est requis.\n",
    "\n",
    "CE5 Vous avez défini sa stratégie d’élaboration d’un modèle pour répondre à un besoin métier. Cela signifie dans ce projet que :\n",
    "\n",
    "l’étudiant a présenté son approche méthodologique de modélisation dans son support de présentation pendant la soutenance et est capable de répondre à des questions à ce sujet, si elles lui sont posées.\n",
    "CE6 Vous avez choisi la ou les variables cibles pertinentes.\n",
    "\n",
    "CE7 Vous avez vérifié qu'il n’y a pas de problème de data leakage (c'est-à-dire, des variables trop corrélées à la variable cible et inconnues a priori dans les données en entrée du modèle).\n",
    "\n",
    "CE8 Vous avez testé plusieurs algorithmes de façon cohérente, en partant des plus simples vers les plus complexes (au minimum un linéaire et un non linéaire).\n",
    "\n",
    "\n",
    "\n",
    "Évaluer les performances des modèles d’apprentissage supervisé selon différents critères (scores, temps d'entraînement, etc.) en adaptant les paramètres afin de choisir le modèle le plus performant pour la problématique métier.\n",
    "\n",
    "CE1 Vous avez choisi une métrique adaptée pour évaluer la performance d'un algorithme (par exemple : R2 ou RMSE en régression, accuracy ou AUC en classification, etc.). Dans le cadre de ce projet, cela signifie que :\n",
    "\n",
    "Vous avez mis en oeuvre un score métier pour évaluer les modèles et optimiser les hyperparamètres, qui prend en compte les spécificités du contexte, en particulier le fait que le coût d’un faux négatif et d’un faux positif sont sensiblement différents.\n",
    "CE2 Vous avez exploré d'autres indicateurs de performance que le score pour comprendre les résultats (coefficients des variables en fonction de la pénalisation, visualisation des erreurs en fonction des variables du modèle, temps de calcul...).\n",
    "\n",
    "CE3 Vous avez séparé les données en train/test pour les évaluer de façon pertinente et détecter l'overfitting.\n",
    "\n",
    "CE4 Vous avez mis en place un modèle simple de référence pour évaluer le pouvoir prédictif du modèle choisi (dummyRegressor ou dummyClassifier).\n",
    "\n",
    "CE5 Vous avez pris en compte dans sa démarche de modélisation l'éventuel déséquilibre des classes (dans le cas d'une classification).\n",
    "\n",
    "CE6 Vous avez optimisé les hyper-paramètres pertinents dans les différents algorithmes.\n",
    "\n",
    "CE7 Vous avez mis en place une validation croisée (via GridsearchCV, RandomizedSearchCV ou équivalent) afin d’optimiser les hyperparamètres et comparer les modèles. Dans le cadre de ce projet :\n",
    "\n",
    "une cross-validation du dataset train est réalisée ;\n",
    "un premier test de différentes valeurs d’hyperparamètres est réalisé sur chaque algorithme testé, et affiné pour l’algorithme final choisi ;\n",
    "tout projet présentant un score AUC anormalement élevé, démontrant de l’overfitting dans le GrisSearchCV, sera invalidé (il ne devrait pas être supérieur au meilleur de la compétition Kaggle : 0.82).\n",
    "CE8 Vous avez présenté l'ensemble des résultats en allant des modèles les plus simples aux plus complexes. Vous avez justifié le choix final de l'algorithme et des hyperparamètres.\n",
    "\n",
    "CE9 Vous avez réalisé l’analyse de l’importance des variables (feature importance) globale sur l’ensemble du jeu de données et locale sur chaque individu du jeu de données.\n",
    "\n",
    "\n",
    "\n",
    "Définir et mettre en œuvre un pipeline d’entraînement des modèles, avec centralisation du stockage des modèles et formalisation des résultats et mesures des différentes expérimentations réalisées, afin d’industrialiser le projet de Machine Learning.\n",
    "CE1 Vous avez mis en oeuvre un pipeline d’entraînement des modèles reproductible.\n",
    "\n",
    "CE2 Vous avez sérialisé et stocké les modèles créés dans un registre centralisé afin de pouvoir facilement les réutiliser.\n",
    "\n",
    "CE3 Vous avez formalisé des mesures et résultats de chaque expérimentation, afin de les analyser et de les comparer\n",
    "\n",
    "\n",
    "\n",
    "Mettre en œuvre un logiciel de version de code afin d’assurer en continu l’intégration et la diffusion du modèle auprès de collaborateurs.\n",
    "CE1 Vous avez créé un dossier contenant tous les scripts du projet dans un logiciel de version de code avec Git et l'a partagé avec Github.\n",
    "\n",
    "CE2 Vous avez présenté un historique des modifications du projet qui affiche au moins trois versions distinctes, auxquelles il est possible d'accéder.\n",
    "\n",
    "CE3 Vous avez tenu à jour et mis à disposition la liste des packages utilisés ainsi que leur numéro de version.\n",
    "\n",
    "CE4 Vous avez rédigé un fichier introductif permettant de comprendre l'objectif du projet et le découpage des dossiers.\n",
    "\n",
    "CE5 Vous avez commenté les scripts et les fonctions facilitant une réutilisation du travail par d'autres personnes et la collaboration.\n",
    "\n",
    "\n",
    "\n",
    "Concevoir et assurer un déploiement continu d'un moteur d’inférence (modèle de prédiction encapsulé dans une API) sur une plateforme Cloud afin de permettre à des applications de réaliser des prédictions via une requête à l’API.\n",
    "\n",
    "CE1 Vous avez défini et préparé un pipeline de déploiement continu.\n",
    "\n",
    "CE2 Vous avez déployé le modèle de machine learning sous forme d'API (via Flask par exemple) et cette API renvoie bien une prédiction correspondant à une demande.\n",
    "\n",
    "CE3 Vous avez mis en œuvre un pipeline de déploiement continu, afin de déployer l'API sur un serveur d'une plateforme Cloud.\n",
    "\n",
    "CE4 Vous avez mis en oeuvre des tests unitaires automatisés (par exemple avec pyTest).\n",
    "\n",
    "CE5 Vous avez réalisé l'API indépendamment de l'application qui utilise le résultat de la prédiction.\n",
    "\n",
    "\n",
    "\n",
    "Définir et mettre en œuvre une stratégie de suivi de la performance d’un modèle en production et en assurer la maintenance afin de garantir dans le temps la production de prédictions performantes.\n",
    "\n",
    "CE1 Vous avez défini une stratégie de suivi de la performance du modèle. Dans le cadre du projet :\n",
    "choix de réaliser a priori cette analyse sur le dataset disponible : analyse de data drift entre le dataset train et le dataset test.\n",
    "\n",
    "CE2 Vous avez réalisé un système de stockage d’événements relatifs aux prédictions réalisées par l’API et une gestion d’alerte en cas de dégradation significative de la performance. Dans le cadre du projet :\n",
    "choix de réaliser a priori cette analyse analyse de data drift, via une simulation dans un notebook et création d’un tableau HTML d’analyse avec la librairie evidently.\n",
    "\n",
    "CE3 Vous avez analysé la stabilité du modèle dans le temps et défini des actions d’amélioration de sa performance. Dans le cadre de ce projet :\n",
    "analyse du tableau HTML evidently, et conclusion sur un éventuel data drift."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1FpefMnpx1QrWxHvQHv_Km0XsNPZwS-GH",
     "timestamp": 1707857231301
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
